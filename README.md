# Aero-Gesture

### **Empowering Accessibility Through Eye-Tracking Technology**

---

## 🚀 Project Overview

**Aero-Gesture** is a groundbreaking initiative designed to revolutionize the way physically challenged individuals interact with computers. By harnessing the power of advanced eye-tracking technology, Aero-Gesture allows users to control mouse functions purely through eye movements, offering an intuitive, hands-free computing experience.

---

## 🎯 Key Features

- **👁️ Eye-Tracking Precision**: Leverages cutting-edge eye-tracking technology to accurately detect and interpret eye movements, ensuring precise control.

- **🖱️ Mouse Control**: Converts eye movements into mouse actions, enabling users to move the cursor, click, and scroll with ease.

- **💻 User-Friendly Interface**: Features a simple, accessible interface designed to cater to users of all tech proficiency levels.

- **⚙️ Customization Options**: Offers adjustable settings for sensitivity and responsiveness, allowing users to tailor the experience to their specific needs.

- **📈 Real-Time Feedback**: Provides instant feedback on eye movements, helping users refine their control and improve their interaction over time.

---

## 🛠️ Use Cases

- **♿ Accessibility**: Enhances the ability of individuals with physical disabilities to operate computers independently and effectively.

- **👐 Hands-Free Computing**: Ideal for scenarios where traditional input devices are impractical, offering an innovative alternative for control.

- **💪 Rehabilitation**: Serves as a valuable tool in therapeutic environments, aiding in the rehabilitation of patients with motor impairments.

---

## 🛠️ Getting Started

## 🛠️ Prerequisites

Before running the Aero-Gesture project, make sure your environment is set up with the following tools and libraries:

1. **Anaconda Python**  
   *Recommended*: Use Anaconda for managing virtual environments and package installations.

2. **OpenCV-Python**  
   *For Video Capture*:  
   ```bash
   pip install opencv-python
3. **NumPy**  
   *For Mathematical Operations*:  
   ```bash
   pip install numpy
6. **PyWin32**  
   *For Screen Size Detection*:  
   ```bash
   pip install pywin32
7. **PyQt5**  
   *For Building User Interface*:  
   ```bash
   pip install pyqt5
8. **Dlib**  
   *For Facial Landmarks Detection*:  
   ```bash
   pip install dlib
*Note*:For installation of Dlib library make sure you have python version 3.8 or below, from version 3.9 dlib library is deprecated. Currently we are working on that issue.
6. **Cmake**  
   *Required for Installing Dlib*:  
   ```bash
   pip install cmake






1. **🔽 Installation**: Download and install the Aero-Gesture software requirements as mentioned above. Follow the guidelines.
  
2. **⚙️ Setup**: Launch the application and follow the guided calibration process to configure the eye-tracking system.

3. **🔧 Customization**: Adjust the sensitivity, responsiveness, and other settings to match your preferences and needs.

4. **🚀 Usage**: Begin controlling your computer with just your eyes! Explore the freedom and accessibility Aero-Gesture brings to your digital interactions.

---

## 🌟 Contributing

We welcome contributions from the community! If you're interested in improving Aero-Gesture, please check out our [contribution guidelines](#).

---

## 📄 License

Aero-Gesture is licensed under the [MIT License](#). See the LICENSE file for more details.

---

## 📞 Contact

For any inquiries, feedback, or support, please reach out to us via [email](mailto:syedabdulkareemahmed@gmail.com).

---

Unlock the potential of hands-free computing with **Aero-Gesture**—where technology meets accessibility.
